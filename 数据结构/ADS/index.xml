<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/ADS%E7%BB%AA%E8%AE%BA/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/ADS%E7%BB%AA%E8%AE%BA/</guid>
      <description>ADS绪论#高级数据结构与算法分析主要包括三块问题：
动态查找问题#**总体目的：**查找树且完全二叉树（降低高度）。
难度过大，因此数据结构核心目标：有一定自由度。因此需要考虑如何进行树的平衡。
高级堆（优先队列问题）#**总体目的：**插入任意&amp;amp;删除最小/最大。
**结构特性：**完全二叉树（structure property）
**排序特性：**结点上满足堆的条件（所在子树最大/最小）（order property）。
**新问题：**云计算，每个云端服务器管理一个堆，本质上为资源整合。（弹性计算）
​ 云计算的调度问题，把正在计算的任务迁移到其他机器，使其最高效运转，即两个优先队列的合并问题。
算法思想#包括分治算法、动态规划、贪婪算法、NPC问题……
大致归为两类：
经典算法：如贪婪算法、分治算法…… 非经典算法：寻找次优解，如加速、并行…… </description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/B&#43;%E6%A0%91/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/B&#43;%E6%A0%91/</guid>
      <description>B+树#概述#常用于数据库、文件系统。大量数据通常存储在磁盘中而非主存，然而磁盘中查找文件速度较慢，为提升速度需要将存储空间划分为很多个block。
B树是搜索树的一种，与二叉搜索树不同。B树包括原始B树、B+树、B-树等。
定义#order为M的树。结构特性如下：
根节点是叶子节点或有2到M个孩子。 除根节点外所有的非叶子节点有**[M/2, M]**个孩子。 所有叶子节点深度相同。 从底层向上层构建，平衡性非常好。
所有真实数据都存放在叶子节点中。
每个中间节点包括M个儿子指针和M-1个key，key存放除第一个子节点外的每个子节点中最小的元素值。
所有叶子节点为从小到大的顺序。
查找操作#与二叉搜索树类似，从根节点开始，比较节点的key值和要查找的值。
插入操作#首先查找到将要插入的叶子节点位置。
若满足B+树的节点数要求，直接插入即可。
若不满足，则分裂成两个叶子节点，并更新父节点的key值。
若导致父节点也不满足节点数要求，则继续向上分裂。
存在问题：不断低效插入导致高度增加较快。此时可以优先考虑未满的叶子节点进行插入，使尽可能多的叶子节点达到full状态。
代码实现#$$T(M,N)=O((\frac{M}{logM})logN)$$
$$T_{Find}(M,N)=O(logN)$$
$$Depth(M,N)=O(log_\frac{M}{2}N)$$
根据时间复杂度公式，并不是M越大越高效。实际结果表明，M=3或4时表现最佳。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/NP%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/NP%E9%97%AE%E9%A2%98/</guid>
      <description>NP问题#回顾#FDS中提到的问题：
欧拉回路：不重复地遍历所有边。使用DFS算法，简单。 **哈密顿回路：**不重复地遍历所有点。困难。 **单源无权重最短路径问题：**使用BFS算法，简单。 **单源无权重最长路径问题：**困难。 “困难”表示尚未得知能保证在多项式时间内解决的算法。
问题的难易程度#最简单：$O(N)$线性时间
最困难：不能解决问题。（undecidable problems）
Decidability：可判定性。
Kurt Godel证明当前的系统不完备，即存在无法用现有定理解释的问题。一种可选方法是每遇到一个此类问题，都将其定义为true或false，但同样可以证明这种操作是无限的。
举例：
图灵停机问题（halting problem）：是否能使C编译器检查出所有无限循环？
**答案：**不能。
**注意：**停机问题是不可解问题，不是NPC或NP问题。
**证明：**实质上是无法证明Loop(Loop)的结果是循环还是不循环。
时间复杂度#时间复杂度分为两种级别，其中后者的复杂度无论如何都远远大于前者：
一种是$O(n)$，$O(logn)$，$O(n^a)$等，称为多项式级的复杂度，因为它的规模n出现在底数的位置；
另一种是$O(a^n)$和$O(n!)$型复杂度，属于非多项式级，其复杂度计算机往往不能承受。
概念引入#**确定性图灵机（Deterministic Turing Machine）：**根据当前的指令和状态选择唯一的下一条要执行的指令。 **非确定性图灵机（Nondeterministic Turing Machine）：**可以在一定集合中任意选择下一步，如果存在一种选择能最终导向结果，图灵机会做出正确的选择。（即非常聪明的图灵机） 定义#P问题是可以通过确定性图灵机，在多项式时间内得出结果的问题。
NP问题是可以通过非确定性图灵机，在多项式时间内得出结果的问题。
即如果能够在多项式时间内证明一个解是正确的，那么非确定性图灵机一定能选择出正确结果。（easy to check）
举例#哈密顿通路问题，可以在$O(N)$时间内验证一个回路是否不重复地遍历了所有结点，因此是一个NP问题。 但不是所有可选择的问题（decidable problems）都是NP问题。例如，判断一个图是否存在哈密顿通路不属于NP问题。
分类#**P类问题：**存在多项式时间算法的问题。 (Polynominal，多项式)
**NP问题：**能在多项式时间内验证得出一个正确解的问题。 (Nondeterministic Polynominal，非确定性多项式)
==P类问题是NP问题的子集，因为存在多项式时间解法的问题，总能在多项式时间内验证他。==
通俗来讲，不知道这个问题是不是存在多项式时间内的算法，所以叫non-deterministic非确定性，但是我们可以在多项式时间内验证并得出这个问题的一个正确解。（注意是不知道而不是不存在）
约化（Reducibility）：具有传递性，如A约化到B，B约化到C，A就可以约化到C，同时不断约化下去，可知一定会存在一个最大的问题，只需要解决了这个问题，那其下的所有问题也就解决啦。如一元一次方程可以约化成一元二次方程。
引到NP问题里就是，对于同一类的所有的NP类问题，若他们都可以在多项式时间内约化成最难的一个NP类问题，（我们直观的认为，被约化成的问题应具有比前一个问题更复杂的时间复杂度）当我们针对这个时间复杂度最高的超级NP问题要是能找到他的多项式时间算法的话，那就等于变向的证明了其下的所有问题都是存在多项式算法的，即NP=P。
**NPC问题：**存在这样一个NP问题，所有的NP问题都可以约化成它。 （Nondeterminism Polynomial Complete，完全NP问题）
格式化定义：
对于一个最优问题，存在两种模式，normal version需要回答出最优解，而decision version仅仅判断是或否。
==需要满足两个条件：①是一个NP问题 ②所有NP问题可以在多项式时间内约化成它。==</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/Splay%E6%A0%91/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/Splay%E6%A0%91/</guid>
      <description>Splay Tree#目标#从空树开始的任何M个连续操作的最大时间开销为O(Mlog N)。（不表示所有操作均为O(log N)，实际上是amortized time为O(logN)）
AVL树属于Splay树。因为AVL对于所有操作的时间复杂度均为O(log N)。
amortized time：摊还时间
核心思想#最坏情况为O(N)，但总时间保持不变。为避免连续多次最坏情况，出现过一次最坏情况的点，下次访问时一定需要到达最好情况。
Splay树定义了这种移动方法：每次访问一个节点后，将其使用AVL树的规则翻转至根节点。
不考虑平衡情况。
查找方法#使用single-rotation#存在的问题：其他节点被换到更低的位置
最坏情况：依次插入1……N，最终的树形式仍然非常不平衡。循环查找1……N，时间复杂度会非常坏。
使用double-rotation#不仅考虑父子节点（X、P），同时加上祖父节点（G）。
三种情况：
P是根节点：X和P进行single-rotation
P不是根节点：
zig-zag：
zig-zig：
使用double-rotation的方式可以大致将最底层的深度减半，是更好的选择。
删除方法#四个步骤：
首先查找X：此时X为根。
删除X：得到左右两个子树。
找到左子树中的最大值：这个最大值成为左子树的根，且没有右子树。
将原右子树连接到左子树上。
Splay树 &amp;amp; AVL树#Splay树实现更简单（不需要时刻考虑BF）</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E4%BA%8C%E9%A1%B9%E9%98%9F%E5%88%97/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E4%BA%8C%E9%A1%B9%E9%98%9F%E5%88%97/</guid>
      <description>二项队列#定义#不是单个的堆结构的树，而是堆结构树的集合，成为森林。其中的每棵堆结构树都是一个二项树。
height为0的二项树只有一个节点。
height为k的二项树成为$$B_k$$，由一个$$B_{k-1}$$树连接到另一个$$B_{k-1}$$树的根节点上得到。
规律：$$B_k$$树有k个儿子，包含$$2^k$$个节点，深度为d处的节点数为$$C^k_d$$。
结论：任意大小的优先队列都能用唯一的二项树集合表示。
操作#FindMin#找到最小值，遍历查找所有根中的最小值即可，最多共有$$logN$$个根节点，时间复杂度为$$O(logN)$$。
可以选择记录最小值所在的根，若更改则更新，此时时间复杂度为$$O(1)$$。
然而若常见操作为delete min而不是find min，将会频繁的更新，用途不显著。
Merge#类似于二进制加法。合并时可能由多种选择，不同选择结果不同，无硬性规定。
合并时需确保新的根节点为较小的根。
时间复杂度取决于树的数量，为$$O(logN)$$。
必须将合并后的树进行按高度排序，而非按key值排序。
Insertion#插入属于特殊的合并操作，时间复杂度同样为$$O(logN)$$。
若最小的不存在的树是$$B_i$$，则时间复杂度为$$T_p=Const*(i+1)$$。
向初始为空的二项队列中插入N次，会发生最坏情况为$$O(N)$$，因此平均时间为常数时间。
DeleteMin#FindMin in $$B_k$$。$$O(logN)$$ 在二项队列中移除$$B_k$$。$$O(1)$$ 移除$$B_k$$的根节点。$$O(logN)$$ 合并两个二项队列。$$O(logN)$$ 因此，总时间复杂度为$$O(logN)$$。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</guid>
      <description>倒排索引#概述#AVL树、Splay树、红黑树、B+树等数据结构的核心目标是在数据量很大时提高搜索查找的速度。
倒排索引用于理解和评价比较搜索引擎。
构建搜索引擎#Term-Document关联矩阵#行为词，列为文件，表示某个词是否出现在某个文件中。
合并两个词查找对两行按位取与即可。
**存在的问题：**矩阵大小会很大且包含很多0。
解决：使用索引（inverted file index）。
倒排索引#索引定义#类似指针，用于在文档中存储某个给定单词的地址的方法。
倒排文件#包括一系列指针，指向某个单词出现过的所有文件。
括号中表示这一单词在第几个文件中的第几个单词的位置。
问题：为什么posting list中要存储单词出现的次数（times）？
计算机在搜索时，从出现频率最小的单词开始，以节省查找时间。
索引生成#在爬虫爬取所有网页（理解为文件）后，遍历所有文件，生成索引。
较难解决的问题：
read阶段：如何判断一个词是一个词。 解决：停止词 find阶段：如何快速查找一个词。 解决：搜索树或哈希 insert阶段：如何快速查找一个词的位置并插入。解决：搜索树或哈希 write阶段：如何存储索引。 解决：存储到磁盘上 read阶段#word stemming
将一个单词转换为它的词干或词根。
stop word
经常出现的词，几乎所有文件都会包含，如the、a、it等等。无效索引，称为停止词，需要从原始文件中剔除。
find和insert阶段#搜索树
B+树、B-树等。
哈希
设计哈希函数。
哈希和搜索树相比的优缺点
在搜索单个单词时，哈希要更快；按一定顺序搜索哈希不能实现（如系列词搜索）。
存储阶段#若存储空间不够时：
在遍历时判断是否内存超限，若是，将当前块写回，并释放内存开启新的块。
遍历结束后按块将block index与总的倒排索引合并，为提高效率，块之间通常保持一定顺序。
分布式索引#distributed index，用于网页级别的索引，数据量很大。
由多个节点组成，每个节点保存一个子集的索引集合。
关键在于如何定义“子集”。
关键词分区索引（term-partitioned index）</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95/</guid>
      <description>分治算法#</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</guid>
      <description>动态规划（DP）#动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。
步骤：
找到最优子结构 递归地定义状态转移方程（最终结果与子结构结果的关系） 找到子问题的最优解 核心：使用表代替递归。
time memory tradeoff：
例一：斐波那契数列#$$ F(N)=F(N-1)+F(N-2) $$
递归存在的问题：F0、F1、F2……重复计算多次，导致时间复杂度很高。
解决方式：保存前两步的斐波那契数，每步依次更新。
例二：矩阵相乘优先排序#不同顺序计算所需的时间不同。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%A4%96%E9%83%A8%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%A4%96%E9%83%A8%E6%8E%92%E5%BA%8F/</guid>
      <description>外部排序（external sorting）#排序大数，当无法完全加载到内存中时，数据存储在一个或多个磁盘中。
无法简单使用快速排序，解决办法是将数据按顺序存储，使用指针同方向遍历。
使用归并排序，需要三个头指针，每次每个指针移动一次。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%B1%80%E9%83%A8%E6%90%9C%E7%B4%A2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%B1%80%E9%83%A8%E6%90%9C%E7%B4%A2/</guid>
      <description>局部搜索（Local Search）#同样是使用近似方法解决问题。特点是关注局部最优解。
初始猜测 → 搜索局部最优解 → 用局部最优解替换上一步猜测 → 循环。
需要考虑的要素：①初始点的选择 ②步长的选择
是否能在有限步数内终止程序？
概念#Local#定义neighborhoods为当前点周围一个可以达到的集合。 局部最优解为neighborhoods集合中的最优选择。 Search#从一个可行解开始，找到其neighborhoods中的最优解。 若没有更优则停止程序。 邻域关系#$S\sim S&amp;rsquo;$：$S&amp;rsquo;$是$S$的邻域内的解（neighboring solution）。即$S$可以通过小范围修改得到$S&amp;rsquo;$。
$N(S)$表示$S$的邻域，即集合${S&amp;rsquo;:S\sim S&amp;rsquo;}$。
Gradient descent：梯度下降法。
实例1：Vertex Cover问题#Decision Version：
给出无向图$G=(V,E)$和整数$K$，是否存在节点集合$V&amp;rsquo;\subseteq V$使得$|V&amp;rsquo;|$最大为$K$，且$G$中的每条边至少有至少有一个节点属于$V&amp;rsquo;$？
Optimazition Version：
给出无向图$G=(V,E)$，找到一个最小集合$S\subseteq V$使得$G$中的每条边至少有至少有一个节点属于$S$？
要素：
可行解集合$FS$：所有满足vertex covers的解集合。显然$V\in FS$。
开销：$cost(S)=|S|$。
局部：$S&amp;rsquo;$可以由$S$加或减一个节点得到。由于要使开销最小，因此选择“减”一个节点。
每个$S$最多有$|V|$个邻域（删除每个节点）。
搜索：从$S=V$开始，删除一个节点，并判断$S&amp;rsquo;$是否是开销更小的vertex cover。
Case 0：只有节点没有边#只有一个全局最优解。此时S为空集。
Case 1：中心节点cover所有边#显然全局最优解为只有中心节点的集合。但若从所有节点开始，第一次就删除了中心节点，则无法删除剩余任何一个节点。
Case 2：节点直线排列没有支路#显然中间三个节点为开销最少的vertex cover。但若第一步删除了这三个节点之一，无法删除其他两个节点。
**存在的问题：**无法撤回上一步操作，很容易陷入局部最优后终止程序。
改进：Metropolis算法。
Metropolis算法#将“删除一个节点”修改为随机选择邻域内所有解，即可以增加节点。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%B7%A6%E5%BC%8F%E5%A0%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%B7%A6%E5%BC%8F%E5%A0%86/</guid>
      <description>左式堆#目标：#减少合并堆的时间复杂度到O(N)。
堆：结构特性（完全二叉树）+排列特性（最小堆）
其他堆存在的问题：若用数组存储，时间复杂度为θ(N)，不是上界；若用指针存储，找到下一条指针的过程所有操作时间都将增加。
概述#order property：与二叉堆相同，最小值在上。
structure property：不平衡二叉树。
定义#null path length：#Npl(X)，表示任何节点X到没有两个儿子的节点的最短路径长度。定义Npl(NULL)=-1。（叶子节点的Npl为0）
Npl计算：从底层向顶层扩展。公式如下：
==Npl(X) = min { Npl(C) + 1 for all C as children of X }==
structure property#对于每个节点X，其左儿子的Npl大于等于右儿子的Npl。更倾向于向左延伸。
定理#若右路径包含r个节点，则左式堆至少包含$$2^r$$个节点。
若左式堆包含N个节点，则右路径最多包含$$log(N+1)$$个节点。
因此，若能够实现所有操作均在右路径上进行，则可以限制操作的时间复杂度。
困难情况：插入和合并。又因为插入属于合并的特殊情况，因此只需解决合并问题即可。
实现原理#节点数据结构#element、left pointer、right pointer、Npl
实例（递归求解）#首先比较根节点大小，较小的一方不变。即将H2与H1的右子堆合并。Merge(H1-&amp;gt;right, H2)
将得到的新堆赋值给原H1的右子堆。Attach(H2, H1-&amp;gt;right)
如果不符合左式堆条件，交换左右子堆。Swap(H1-&amp;gt;left, H1-&amp;gt;right)
代码实现#时间复杂度：$$T_p=O(logN)$$
实例（迭代求解）#选择根节点较小的堆，左子堆不变。 两个堆的右路径按大小排序，依次插入到上一步选择出的堆的右子堆上。（每个节点与其左子堆绑定）（此时并不符合左式堆） 对于右路径，从底层到顶层，检查Npl，如果不符合左式堆则调换左右子堆。 对于递归和迭代，所有操作时间复杂度均为log N。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95/</guid>
      <description>并行算法（Parallel Algorithms）#概述#并行分类#机器级并行（硬件） 处理器并行 流水线 超长指令字（VLIW） 算法级并行 描述并行算法的两个模型#Parallel Random Access Machine（PRAM） Work-Depth（WD) PRAM模型#$n$个进程，共享内存。一个箭头表示一个单位时间访问（读/写/计算）。
定义processor i为$c=a+b$。如下代码表示并行计算$A(i)=B(i)$。其中==pardo==为并行运算的关键字。
for Pi, 1 &amp;lt;= i &amp;lt;= n pardo A(i) := B(i) 存在问题：多个进程同时写同一个内存块。
解决访问冲突
Exclusive-Read Exclusive-Write（EREW）：同时只允许一个进程读或写。 Concurrently-Read Exclusive-Write（CREW）：可以同时读，禁止同时写。 Concurrently-Read Concurrently-Write（CRCW）：可以同时读或写。 Arbitrary rule：随机选择一个进程执行。 *Priority rule（P with the smallest number）：*按优先级选择进程执行。 Common rule：当所有进程写的是同一个值的时候允许。 实例1：加和计算
输入$A(1),A(2),\ldots,A(n)$，输出$A(1)+A(2)+\ldots+A(n)$。
从底层到顶层计算，形成完全二叉树，规律如下：
代码表示：共执行了$log n+2$次操作，每次操作为常数时间。
时间表示：
==标准的PRAM：==每个处理器都看作执行一条指令，即使是idle状态。
==实际上的：==只有部分处理器在工作。
因此标准PRAM存在一些弱点：
没有揭示算法将如何运行在不同数量的处理器上。即加上或减去一些处理器会对算法有怎样的影响。 完全指定处理器的指令分配需要一定程度的细节。 WD模型#每个处理器执行不同条数的指令。
衡量并行算法的性能#***work load：***总操作数$W(n)$。 最坏情况运行时间：$T(n)$。 实例1：Prefix-Sums#输入$A(0),A(1),\ldots,A(n)$，输出$\Sigma_{i=1}^{1}A(i),\Sigma_{i=1}^{2}A(i),\ldots,\Sigma_{i=1}^{n}A(i)$。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E6%96%9C%E5%A0%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E6%96%9C%E5%A0%86/</guid>
      <description>斜堆#概述#左式堆和斜堆的关系类似于AVL树和Splay树的关系。斜堆是左式堆的简化版，不需要考虑Npl。
目标#连续M个操作总时间复杂度为$$O(MlogN)$$。
合并操作#总是交换左右子堆，不考虑Npl。
选择根节点较小的堆不变，将其左子堆换到右子堆的位置，再将原来的右子堆与另一个堆合并后attach到新堆的左子堆上。
当最后一步与空堆合并时，无需交换左右子堆。
注意最终得到的堆不一定是左式堆。
递归求解#迭代求解#分析#斜堆的优势#可以节省存放Npl所需的额外空间，且交换左右子堆时无需比较Npl大小。
准确的右路径长度仍然未知。
摊还分析#插入和删除操作均属于合并操作。只要证明合并的均摊时间复杂度为$$O(logN)$$即可。
势能函数定义：
右子堆节点个数？No，由于最初为空堆，势能为0，后面任何操作势能都会大于0，缺少势能减少的方向（bad luck）的情况。 正确答案：heavy nodes的个数。 heavy nodes定义
对于一个节点，若其右侧的节点总数不小于总节点数的一半（即大于左侧节点总数），则称这个节点为heavy node，代表bad luck的情况；若反之，左侧节点总数大于右侧，则称为light node，代表good luck的情况。
注意：这里的总节点数包括了根节点本身，因此左右子堆节点数相同的点不属于heavy node或light node。
**规律：**heavy或light性质前后发生改变的节点一定在最初的右路径上。
​ 且在右路径上原heavy的节点经过merge后一定会变成light节点。
​ 且在右路径上原light的节点经过merge后不一定会变成heavy节点。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E7%BA%A2%E9%BB%91%E6%A0%91/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E7%BA%A2%E9%BB%91%E6%A0%91/</guid>
      <description>红黑树#概述#AVL树是首个自平衡树，定义了“平衡”的衡量标准（BF）。
Splay树是AVL树的简化版，无需考虑平衡，表现与AVL树相同。
现实应用中存在其他定义“平衡”的方法：如红黑树、B+树，红黑树应用于C++STL中的map等类型。
目标#平衡二叉搜索树。
节点结构如下：
NULL节点也称为NIL。
定义#五个特性#每个节点是红色或黑色中的一个。 根节点为黑色。 每个NULL叶子节点为黑色。 红色节点的两个儿子一定为黑色。 对于每个节点，其到叶子节点的所有简单路径上黑色节点的个数相同。 black_height：从x到叶子节点的黑色节点的个数，不包括root包括NULL。bh(Tree) = bh(root)
internal_nodes：除NIL节点外的结点。
external_nodes：NIL节点。
定理#拥有N个internal_nodes的红黑树，其高度最大为2ln(N+1)。
即使没有AVL更为严格的平衡定义，红黑树也将其高度限制在了O(lgN)的水平。
对于任何节点x，以x为根的所有子树的internal_nodes个数大于等于2^bh(x)^-1。通过数学归纳法证明。
将x替换为root，则sizeof(x) = N，得到N&amp;gt;=2^bh^-1。
bh(Tree) &amp;gt;= h(Tree)/2。
证明：每条路径上，除根节点外，至少有一半的节点时黑色。
N &amp;gt;= 2^bh^-1 &amp;gt;= 2^h/2^-1，证明结束。
插入操作#需要尽可能避免改变红黑树的bh，避免重新平衡。因此新插入的节点颜色应为红色。但再次插入红节点时需要重新平衡，引出三种情况：
Case 1#新节点为红色，父节点为红色，父节点的兄弟节点也为红色。
解决方式：父代所有节点和祖父节点红黑颜色调换。
Case 2#新节点为红色且是父节点的右儿子，父节点为红色，父节点的兄弟节点为黑色。
解决方式：将新节点和其父节点进行一次旋转。
Case 3#新节点为红色且是父亲的左儿子，父节点为红色，父节点的兄弟节点为黑色。
解决方式：首先将父节点和祖父节点互换颜色，再将父节点作为新的根节点进行旋转。
AVL树 &amp;amp; 红黑树#step 1：向二叉搜索树中插入节点。 step 2：从底层到顶层，检查BF/颜色是否符合规定。 最坏情况相同，都需要进行两次rotation。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E8%B4%AA%E5%A9%AA%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E8%B4%AA%E5%A9%AA%E7%AE%97%E6%B3%95/</guid>
      <description>贪婪算法#概述#在Dijkstra算法求解最短路径、Kruskal算法求解最小生成树中都使用了贪婪算法的思想。
用于求解最优问题。通常已知一些约束和最优函数，满足约束的解决方案成为可行方案（feasible solution）。
最优函数值最大的可行方案称为最优方案。
核心思想#每个步骤都选择最优解，上一步选择的结果在后续步骤中不会改变，即不能撤销前面步骤，同时每个选择都应确保方案可行。
注意：
贪婪算法只在当前最优解即为总体最优解时能正确解出最优解，即local optimum = global optimum的gool luck情况。 贪婪算法不能保证结果一定为最优，但它给出的结果一定与最优结果取值相近，即启发式算法（heuristics）。因此当寻找实际的最优解需要耗费大量时间时，直觉上可以采用贪婪算法。good enough。 活动选择问题#给出需要共用同一资源的一系列时间，记为$$S={a_1,a_2,……,a_n}$$。每个事件$$a_i$$发生的时间间隔为$$[s_i,f_i)$$。
对于事件$$a_i$$和$$a_j$$，若有$$s_i\ge f_j$$或$s_j\ge f_j$，则称为两个事件兼容，即两个事件的时间不重合。
假设：$f_1\le f_2\le……\le f_{n-1}\le f_n$。
目标是选择能够兼容发生的事件的最大子集。
例：
最多能兼容4个事件，为最优解，且最优结果不唯一。
动态规划求解#定义$S_{ij}$为起始时间在$a_i$开始之后且结束时间在$a_j$结束之前的解。
将$S_{ij}$分为两个子问题，进行divide-conquer。
时间复杂度为$O(N^3)$。
贪婪算法求解#不同的贪婪规则：
挑选在不与前面重合的前提下，最早开始的事件。
挑选在不与前面重合的前提下，时间最短的事件。
挑选在不与前面重合的前提下，与其余事件冲突最少的事件。
挑选在不与前面重合的前提下，最早结束的事件。即尽快使资源得到释放。
正确性证明#需要证明：①算法的结果满足时间不重合。 ②结果最优。
定理
对于任意非空的子问题$S_k$，若$a_m$是$S_k$中最早结束的事件，则$a_m$一定是$S_k$最优解的集合中的元素。（最优解不一定唯一）
证明：
设$A_k$为某一最优解集合（不一定包括$a_m$），设$a_{ef}$为某个最优解集合中结束时间最早的一个事件。
①若$a_m$与$a_{ef}$是同一个事件，则无需额外证明。
②否则，用$a_m$替换$a_{ef}$，得到新的集合$A_k&amp;rsquo;$。由于$a_m$是整个集合中最早结束的事件，因此有$f_m\le f_{ef}$。
显然$a_m$与这一解集合中的其他事件都不冲突，因此$A_k&amp;rsquo;$是一个新的最优解集合。
最终解决办法
每次选择最先结束的事件，尾递归可以转换为迭代求解，因此总的时间复杂度为：$O(NlogN)$。
问题：能否将“最先结束”这一条件替换为“最迟开始”？
答：可以，能够通过证明。
另一种DP求解#其中$c_{1,j}$表示从第一个事件到第j个事件间的最优解，$k(j)$表示在$a_j$开始前结束且距离$a_j$最近的事件。
相较于第一种动态规划，在证明了上述定理的基础上，把i、j双重循环简化为单层循环。
$c_{1,j-1}$表示不选取$a_j$时的最优解，$c_{1,k(j)}$表示在$a_j$之前与$a_j$不冲突的最优解，$c_{1,k(j)}+1$表示选取$a_j$时的最优解。
如果修改问题为：每个事件带有一定权重，而最优解指的是所有事件权重之和最大的解
此时动态规划算法依然是正确的，但贪婪算法不一定正确。
贪婪策略的要素#将最优问题分步骤解决，使得每步中需要做出一个选择。 需要证明，总存在至少一个最优解包含贪婪算法的选择（与上述正确性证明类似），这保证了贪婪算法是安全可行的。 需要证明，存在最优子结构。即用贪婪算法选择出的最优子解+剩余部分的最优子解=原问题的最优解。 霍夫曼编码问题#问题描述#霍夫曼编码通常用于文件压缩。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E8%BF%91%E4%BC%BC%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E8%BF%91%E4%BC%BC%E7%AE%97%E6%B3%95/</guid>
      <description>近似算法（Approximation）#概述#用于解决困难问题，如NPC问题。
对于NPC问题的处理方法：
N很小，$O(2^N)$也可以接受。
总体问题很复杂，但可以在多项式时间解决一些重要的特殊情况。
寻找一个能在多项式时间得出的次优解（near-optimal solution）。→ 渐近算法
近似比例（approximation radio）#定义#若对于任意大小的输入$n$，渐近算法求解的开销$C$不超过最优解开销$C*$的$\rho (n)$因子，则该算法的渐近比例为$\rho(n)$。称为**$\rho(n)$渐近算法**。
近似方案（approximation scheme）#一个最优解问题的渐近方案是一个输入为问题instance和一个正数$\epsilon$的渐近算法，使其对于任何确定的$\epsilon$，都是一个$(1+\epsilon)$渐近算法。
若对于任意确定的$\epsilon &amp;gt;0$，渐近方案能在多项式时间内得出结果，则称为PTAS（polynomial-time approximation scheme）。
通常PTAS的时间复杂度形如$O(n^{2/\epsilon})$。随着$\epsilon$减小，时间复杂度增大。
有一种特殊情况复杂度形如$O((1/\epsilon)^2n^3)$，优于上面的情况，这种PTAS称为FPTAS（fully polynomial-time）。
fully表示时间复杂度中的两个变量$n$和$\epsilon$都是多项式形式。
实例1：装箱问题#Bin Packing，NP-Hard问题。
给出大小分别为$S_1,S_2,……S_N$的$N$个物品，每个$S_i$都有$0&amp;lt;S_i\le 1$。每个背包有单位空间，将这些物品装入数量最少的背包里。
**decision version：**给出K个背包和N个物品的大小，求解是否能装下。
NP-Compelete问题。
Next Fit#依次遍历每个物品，若上一个背包能放下则放入上一个背包，否则新开一个背包。线性时间复杂度。
定理：
若$M$为物品集$I$的最优解（即最少背包数），则Next Fit近似算法的结果一定不超过$2M-1$，且存在解法使得结果刚好等于$2M-1$。
证明：
反证法：即证明若NF算法结果为$2M$或$2M+1$，则最优解的结果一定大于等于$M+1$。
近似比例为2，需要更好的方案。
First Fit#搜索第一个满足能装下该物品的背包，若存在，则放入该背包中；若不存在，则新开一个背包。时间复杂度为$O(NlogN)$。
定理：
若$M$为物品集$I$的最优解（即最少背包数），则First Fit近似算法的结果一定不超过$17M/10$，且存在解法使得结果刚好等于$17(M-1)/10$。
近似比例为1.7。
Best Fit#将物品放置在“最拥挤”的背包里，即放下物品后剩余空间最小。时间复杂度为$O(NlogN)$。结果同样$\le 1.7M$。
Worst Fit#将物品放置在“最空闲”的背包里，即放下物品后剩余空间最大。
对比#另一个例子：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E9%9A%8F%E6%9C%BA%E5%8C%96%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ArcticPirateL.github.io/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ADS/%E9%9A%8F%E6%9C%BA%E5%8C%96%E7%AE%97%E6%B3%95/</guid>
      <description>随机化算法（Randomized Alogorithms）#随机化的定义#the world behaves randomly：随机生成乱序的输入并使用传统算法解决 $\Rightarrow$ 平均情况分析（Average-case Analysis）。 the algorithm behaves randomly：当输入情况最坏时算法采用随机决策的方式求解。 两种随机化目标：
**efficient algorithm：**yield the correct answer with ==high probability==.注重效率高。 **deterministic algorithm：**always correct and run efficiently ==in expectation==.注重正确性。 概率前置知识#$Pr[A]$：事件$A$发生的概率。
$\overline A$：事件$A$的补集，即不发生。
$E $：随机变量$X$的期望（平均值）。
$E[X]=\Sigma_{j=0}^{\infin}\ j\cdot Pr[X=j]$。
实例1：Hiring问题#雇佣一个助手，共$N$天，每天面试一个人。
面试开销：$C_i &amp;laquo; $雇佣开销：$C_h$。
分析开销，假设$N$天面试雇佣了$M$个应聘者，则总开销为：$O(NC_i+MC_h)$。目标为使总开销最小化。
原始解法#从0开始，每次遇到更好的应聘者，解雇此前最好的，雇佣当前的。
最坏情况：候选人的质量按升序排列。此时开销约为$O(NC_h)$。
最好情况：候选人的质量按降序排列。
改进方向：
提高解决最坏情况的效率。 尝试避免出现最坏情况。 若候选人随机顺序出现。设$X$为雇佣次数，找到$X$的期望。核心问题是如何知道$Pr[X=j]$。
定义$X_i=\begin{cases} 1 &amp;amp; if \ candidate\ i\ is\ hired \0 &amp;amp; if\ candidate\ i\ is\ NOT\ hired \end{cases} \Rightarrow X=\Sigma_{i=1}^NX_i$ 得到：</description>
    </item>
    
  </channel>
</rss>
